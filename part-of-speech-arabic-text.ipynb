{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11666002,"sourceType":"datasetVersion","datasetId":7321570}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyconll","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:31:14.913802Z","iopub.execute_input":"2025-05-09T12:31:14.914048Z","iopub.status.idle":"2025-05-09T12:31:19.719377Z","shell.execute_reply.started":"2025-05-09T12:31:14.914028Z","shell.execute_reply":"2025-05-09T12:31:19.718382Z"}},"outputs":[{"name":"stdout","text":"Collecting pyconll\n  Downloading pyconll-3.2.0-py3-none-any.whl.metadata (8.0 kB)\nDownloading pyconll-3.2.0-py3-none-any.whl (27 kB)\nInstalling collected packages: pyconll\nSuccessfully installed pyconll-3.2.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install  evaluate  seqeval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:31:23.793397Z","iopub.execute_input":"2025-05-09T12:31:23.794014Z","iopub.status.idle":"2025-05-09T12:31:31.693425Z","shell.execute_reply.started":"2025-05-09T12:31:23.793978Z","shell.execute_reply":"2025-05-09T12:31:31.692468Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.2.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nCollecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.16)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.19.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=b4784bba4a3614aca4d6aaa9995de2be93eec85ec90ccb89c47639446ca8c9ed\n  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\nSuccessfully built seqeval\nInstalling collected packages: fsspec, seqeval, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.3 fsspec-2024.12.0 seqeval-1.2.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pyconll\ndata = pyconll.load_from_file('/kaggle/input/arabic-pos/Arabic_POS.conllu')\n\nreview_sentences = []\npos_tags = []\nunique_pos_tags = set()\n\nfor sentence in data:  \n    sentence_tokens = []  \n    sentence_pos = []\n    \n    for token in sentence:\n        if token.upos is not None:  # Skip if POS is missing\n            unique_pos_tags.add(token.upos)\n            sentence_tokens.append(token.form)\n            sentence_pos.append(token.upos)\n\n    review_sentences.append(sentence_tokens)\n    pos_tags.append(sentence_pos)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:35:32.602118Z","iopub.execute_input":"2025-05-09T12:35:32.602442Z","iopub.status.idle":"2025-05-09T12:35:40.854818Z","shell.execute_reply.started":"2025-05-09T12:35:32.602420Z","shell.execute_reply":"2025-05-09T12:35:40.853955Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"\nresult = ' '.join(review_sentences[5])  \nprint(result)  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:35:43.434372Z","iopub.execute_input":"2025-05-09T12:35:43.435172Z","iopub.status.idle":"2025-05-09T12:35:43.439633Z","shell.execute_reply.started":"2025-05-09T12:35:43.435144Z","shell.execute_reply":"2025-05-09T12:35:43.438965Z"}},"outputs":[{"name":"stdout","text":"و تعذر ل متحدثة ب اسم وزارة الدفاع الالمانية ان تؤكد اليوم السبت هذه المعلومات .\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"labels=list(unique_pos_tags)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:35:44.882669Z","iopub.execute_input":"2025-05-09T12:35:44.883281Z","iopub.status.idle":"2025-05-09T12:35:44.886927Z","shell.execute_reply.started":"2025-05-09T12:35:44.883257Z","shell.execute_reply":"2025-05-09T12:35:44.886094Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"len(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:35:45.798245Z","iopub.execute_input":"2025-05-09T12:35:45.798822Z","iopub.status.idle":"2025-05-09T12:35:45.803625Z","shell.execute_reply.started":"2025-05-09T12:35:45.798794Z","shell.execute_reply":"2025-05-09T12:35:45.802886Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"17"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"labels = ['None' if x is None else x for x in labels]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:35:47.904502Z","iopub.execute_input":"2025-05-09T12:35:47.904768Z","iopub.status.idle":"2025-05-09T12:35:47.909096Z","shell.execute_reply.started":"2025-05-09T12:35:47.904747Z","shell.execute_reply":"2025-05-09T12:35:47.908290Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"len(review_sentences[12]),len(pos_tags[12])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:35:48.308057Z","iopub.execute_input":"2025-05-09T12:35:48.308324Z","iopub.status.idle":"2025-05-09T12:35:48.313514Z","shell.execute_reply.started":"2025-05-09T12:35:48.308306Z","shell.execute_reply":"2025-05-09T12:35:48.312659Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"(12, 12)"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"import pandas as pd\ndf=pd.DataFrame({'tokens': review_sentences, 'pos_tags': pos_tags})\ndf.insert(0, 'id', range(1, len(df) + 1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:35:49.158135Z","iopub.execute_input":"2025-05-09T12:35:49.158415Z","iopub.status.idle":"2025-05-09T12:35:49.167570Z","shell.execute_reply.started":"2025-05-09T12:35:49.158396Z","shell.execute_reply":"2025-05-09T12:35:49.166778Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:35:51.136336Z","iopub.execute_input":"2025-05-09T12:35:51.136621Z","iopub.status.idle":"2025-05-09T12:35:51.148526Z","shell.execute_reply.started":"2025-05-09T12:35:51.136600Z","shell.execute_reply":"2025-05-09T12:35:51.147805Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"   id                                             tokens  \\\n0   1  [برلين, ترفض, حصول, شركة, اميركية, على, رخصة, ...   \n1   2  [برلين, 15, -, 7, (, اف, ب, ), -, افادت, صحيفة...   \n2   3  [و, في, نيسان, /, ابريل, الماضي, ،, تخلت, الدو...   \n3   4  [و, كانت, خسائر, المجموعة, الاسبانية, الرسمية,...   \n4   5  [و, أشارت, صحيفة, الاحد, الى, ان, المستشار, شر...   \n\n                                            pos_tags  \n0  [X, VERB, NOUN, NOUN, ADJ, ADP, NOUN, NOUN, NO...  \n1  [X, NUM, PUNCT, NUM, PUNCT, X, X, PUNCT, PUNCT...  \n2  [CCONJ, ADP, NOUN, PUNCT, NOUN, ADJ, PUNCT, VE...  \n3  [CCONJ, VERB, NOUN, NOUN, ADJ, ADJ, VERB, ADP,...  \n4  [CCONJ, VERB, NOUN, NOUN, ADP, SCONJ, NOUN, X,...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tokens</th>\n      <th>pos_tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>[برلين, ترفض, حصول, شركة, اميركية, على, رخصة, ...</td>\n      <td>[X, VERB, NOUN, NOUN, ADJ, ADP, NOUN, NOUN, NO...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>[برلين, 15, -, 7, (, اف, ب, ), -, افادت, صحيفة...</td>\n      <td>[X, NUM, PUNCT, NUM, PUNCT, X, X, PUNCT, PUNCT...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>[و, في, نيسان, /, ابريل, الماضي, ،, تخلت, الدو...</td>\n      <td>[CCONJ, ADP, NOUN, PUNCT, NOUN, ADJ, PUNCT, VE...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>[و, كانت, خسائر, المجموعة, الاسبانية, الرسمية,...</td>\n      <td>[CCONJ, VERB, NOUN, NOUN, ADJ, ADJ, VERB, ADP,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>[و, أشارت, صحيفة, الاحد, الى, ان, المستشار, شر...</td>\n      <td>[CCONJ, VERB, NOUN, NOUN, ADP, SCONJ, NOUN, X,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Flatten the list of POS tags to fit encoder\nall_pos_flat = [tag for sentence in pos_tags for tag in sentence]\n\nle = LabelEncoder()\nle.fit(all_pos_flat)\n\n# Save mapping for later use (e.g., during inference)\nid2label = {i: label for i, label in enumerate(le.classes_)}\nlabel2id = {label: i for i, label in enumerate(le.classes_)}\n\n# Encode the full dataset\ndf['pos_tags'] = [[label2id[tag] for tag in sentence] for sentence in pos_tags]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:35:53.584855Z","iopub.execute_input":"2025-05-09T12:35:53.585403Z","iopub.status.idle":"2025-05-09T12:35:53.793004Z","shell.execute_reply.started":"2025-05-09T12:35:53.585378Z","shell.execute_reply":"2025-05-09T12:35:53.792362Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"id2label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:35:57.237846Z","iopub.execute_input":"2025-05-09T12:35:57.238160Z","iopub.status.idle":"2025-05-09T12:35:57.243881Z","shell.execute_reply.started":"2025-05-09T12:35:57.238137Z","shell.execute_reply":"2025-05-09T12:35:57.243132Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"{0: 'ADJ',\n 1: 'ADP',\n 2: 'ADV',\n 3: 'AUX',\n 4: 'CCONJ',\n 5: 'DET',\n 6: 'INTJ',\n 7: 'NOUN',\n 8: 'NUM',\n 9: 'PART',\n 10: 'PRON',\n 11: 'PROPN',\n 12: 'PUNCT',\n 13: 'SCONJ',\n 14: 'SYM',\n 15: 'VERB',\n 16: 'X'}"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"df['tokens'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:36:05.657268Z","iopub.execute_input":"2025-05-09T12:36:05.658024Z","iopub.status.idle":"2025-05-09T12:36:05.663156Z","shell.execute_reply.started":"2025-05-09T12:36:05.658000Z","shell.execute_reply":"2025-05-09T12:36:05.662439Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"['برلين',\n 'ترفض',\n 'حصول',\n 'شركة',\n 'اميركية',\n 'على',\n 'رخصة',\n 'تصنيع',\n 'دبابة',\n '\"',\n 'ليوبارد',\n '\"',\n 'الالمانية']"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T01:02:33.659033Z","iopub.execute_input":"2025-05-08T01:02:33.659910Z","iopub.status.idle":"2025-05-08T01:02:33.670133Z","shell.execute_reply.started":"2025-05-08T01:02:33.659885Z","shell.execute_reply":"2025-05-08T01:02:33.669439Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   id                                             tokens  \\\n0   1  [برلين, ترفض, حصول, شركة, اميركية, على, رخصة, ...   \n1   2  [برلين, 15, -, 7, (, اف, ب, ), -, افادت, صحيفة...   \n2   3  [و, في, نيسان, /, ابريل, الماضي, ،, تخلت, الدو...   \n3   4  [و, كانت, خسائر, المجموعة, الاسبانية, الرسمية,...   \n4   5  [و, أشارت, صحيفة, الاحد, الى, ان, المستشار, شر...   \n\n                                            pos_tags  \n0       [16, 15, 7, 7, 0, 1, 7, 7, 7, 12, 16, 12, 0]  \n1  [16, 8, 12, 8, 12, 16, 16, 12, 12, 15, 7, 7, 0...  \n2  [4, 1, 7, 12, 7, 0, 12, 15, 7, 0, 1, 7, 12, 16...  \n3  [4, 15, 7, 7, 0, 0, 15, 1, 7, 8, 0, 4, 15, 8, ...  \n4  [4, 15, 7, 7, 1, 13, 7, 16, 15, 13, 7, 7, 0, 1...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tokens</th>\n      <th>pos_tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>[برلين, ترفض, حصول, شركة, اميركية, على, رخصة, ...</td>\n      <td>[16, 15, 7, 7, 0, 1, 7, 7, 7, 12, 16, 12, 0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>[برلين, 15, -, 7, (, اف, ب, ), -, افادت, صحيفة...</td>\n      <td>[16, 8, 12, 8, 12, 16, 16, 12, 12, 15, 7, 7, 0...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>[و, في, نيسان, /, ابريل, الماضي, ،, تخلت, الدو...</td>\n      <td>[4, 1, 7, 12, 7, 0, 12, 15, 7, 0, 1, 7, 12, 16...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>[و, كانت, خسائر, المجموعة, الاسبانية, الرسمية,...</td>\n      <td>[4, 15, 7, 7, 0, 0, 15, 1, 7, 8, 0, 4, 15, 8, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>[و, أشارت, صحيفة, الاحد, الى, ان, المستشار, شر...</td>\n      <td>[4, 15, 7, 7, 1, 13, 7, 16, 15, 13, 7, 7, 0, 1...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"len(df['tokens'][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T01:02:34.230883Z","iopub.execute_input":"2025-05-08T01:02:34.231652Z","iopub.status.idle":"2025-05-08T01:02:34.236164Z","shell.execute_reply.started":"2025-05-08T01:02:34.231626Z","shell.execute_reply":"2025-05-08T01:02:34.235377Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"13"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"df['pos_tags'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T01:02:34.771127Z","iopub.execute_input":"2025-05-08T01:02:34.771618Z","iopub.status.idle":"2025-05-08T01:02:34.776328Z","shell.execute_reply.started":"2025-05-08T01:02:34.771597Z","shell.execute_reply":"2025-05-08T01:02:34.775650Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"[16, 15, 7, 7, 0, 1, 7, 7, 7, 12, 16, 12, 0]"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"from datasets import Dataset\nfrom sklearn.model_selection import train_test_split\n\n\ntrain_df, tests = train_test_split(df, test_size=0.3, random_state=42)\nval_df,test_df=  train_test_split(tests, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:36:10.942514Z","iopub.execute_input":"2025-05-09T12:36:10.942772Z","iopub.status.idle":"2025-05-09T12:36:12.628798Z","shell.execute_reply.started":"2025-05-09T12:36:10.942755Z","shell.execute_reply":"2025-05-09T12:36:12.627990Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"train_dataset = Dataset.from_pandas(train_df,preserve_index=False)\ntest_dataset = Dataset.from_pandas(test_df, preserve_index=False)\nval_dataset=Dataset.from_pandas(val_df, preserve_index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:36:15.018227Z","iopub.execute_input":"2025-05-09T12:36:15.019021Z","iopub.status.idle":"2025-05-09T12:36:15.152885Z","shell.execute_reply.started":"2025-05-09T12:36:15.018996Z","shell.execute_reply":"2025-05-09T12:36:15.152255Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"train_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:36:15.544335Z","iopub.execute_input":"2025-05-09T12:36:15.544613Z","iopub.status.idle":"2025-05-09T12:36:15.549795Z","shell.execute_reply.started":"2025-05-09T12:36:15.544593Z","shell.execute_reply":"2025-05-09T12:36:15.549161Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'tokens', 'pos_tags'],\n    num_rows: 4252\n})"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"\n#id2label = {i: label for i, label in enumerate(labels)}\n#label2id = {label: i for i, label in enumerate(labels)}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:34:41.187886Z","iopub.execute_input":"2025-05-09T12:34:41.188642Z","iopub.status.idle":"2025-05-09T12:34:41.192542Z","shell.execute_reply.started":"2025-05-09T12:34:41.188618Z","shell.execute_reply":"2025-05-09T12:34:41.191725Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"from transformers import AutoTokenizer, TFAutoModelForTokenClassification\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\n\n# Load model with proper label mapping\nmodel = TFAutoModelForTokenClassification.from_pretrained(\n    \"asafaya/bert-base-arabic\",\n    num_labels=len(le.classes_),        \n    id2label=id2label,             \n    label2id=label2id              \n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:36:25.799493Z","iopub.execute_input":"2025-05-09T12:36:25.799748Z","iopub.status.idle":"2025-05-09T12:36:53.055084Z","shell.execute_reply.started":"2025-05-09T12:36:25.799731Z","shell.execute_reply":"2025-05-09T12:36:53.054339Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/62.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd200cddd81740d59512a0d5a896d939"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/491 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"001beaddcda34bb58e5081727114c550"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/334k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dba124af21924aa0b763829b990ea7a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb7350f645a5438a809257048f52df32"}},"metadata":{}},{"name":"stderr","text":"2025-05-09 12:36:35.075466: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746794195.301451      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746794195.363428      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8833856d7ade419bbd3675cf66e3405a"}},"metadata":{}},{"name":"stderr","text":"I0000 00:00:1746794211.326096      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\nAll PyTorch model weights were used when initializing TFBertForTokenClassification.\n\nSome weights or buffers of the TF 2.0 model TFBertForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"def tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n\n    labels = []\n    for i, label in enumerate(examples[f\"pos_tags\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)  \n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:  \n            if word_idx is None:\n                label_ids.append(-100)\n            elif word_idx != previous_word_idx:  \n                label_ids.append(label[word_idx])\n            else:\n                label_ids.append(-100)\n            previous_word_idx = word_idx\n        labels.append(label_ids)\n\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:36:55.861099Z","iopub.execute_input":"2025-05-09T12:36:55.861808Z","iopub.status.idle":"2025-05-09T12:36:55.867300Z","shell.execute_reply.started":"2025-05-09T12:36:55.861786Z","shell.execute_reply":"2025-05-09T12:36:55.866395Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"tokenized_train = train_dataset.map(tokenize_and_align_labels, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:36:58.591253Z","iopub.execute_input":"2025-05-09T12:36:58.591574Z","iopub.status.idle":"2025-05-09T12:36:59.712422Z","shell.execute_reply.started":"2025-05-09T12:36:58.591551Z","shell.execute_reply":"2025-05-09T12:36:59.711489Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4252 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad6f3132770b46fd876844eac249b70c"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"# Check the structure of the tokenized dataset\nprint(\"Tokenized train dataset features:\", tokenized_train.column_names)\n\n# Access a sample from the tokenized dataset to see the tokenized inputs and labels\nsample = tokenized_train[0]\nprint(\"\\nSample tokenized input:\")\nprint(\"Tokens:\", sample['input_ids'])  # Tokenized IDs\nprint(\"Attention Mask:\", sample['attention_mask'])  # Attention Mask (if used)\nprint(\"Labels:\", sample['labels'])  # Aligned POS tags\n\n# Optionally, convert the token IDs back to words using the tokenizer for readability\nprint(\"\\nDecoded tokens:\")\ndecoded_tokens = tokenizer.decode(sample['input_ids'], skip_special_tokens=True)\nprint(decoded_tokens)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:37:01.512871Z","iopub.execute_input":"2025-05-09T12:37:01.513151Z","iopub.status.idle":"2025-05-09T12:37:01.520214Z","shell.execute_reply.started":"2025-05-09T12:37:01.513131Z","shell.execute_reply":"2025-05-09T12:37:01.519385Z"}},"outputs":[{"name":"stdout","text":"Tokenized train dataset features: ['id', 'tokens', 'pos_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels']\n\nSample tokenized input:\nTokens: [2, 4539, 4445, 30435, 6734, 2061, 2430, 3]\nAttention Mask: [1, 1, 1, 1, 1, 1, 1, 1]\nLabels: [-100, 7, 7, 7, -100, 1, 7, -100]\n\nDecoded tokens:\nارتفاع نسبة المدخنات فى السعودية\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"tokenized_test = test_dataset.map(tokenize_and_align_labels, batched=True)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:37:24.398783Z","iopub.execute_input":"2025-05-09T12:37:24.399445Z","iopub.status.idle":"2025-05-09T12:37:24.532994Z","shell.execute_reply.started":"2025-05-09T12:37:24.399414Z","shell.execute_reply":"2025-05-09T12:37:24.532285Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/365 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23d127f2839144afa63f9cb094d3a783"}},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"tokenized_val = val_dataset.map(tokenize_and_align_labels, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:37:26.938773Z","iopub.execute_input":"2025-05-09T12:37:26.939344Z","iopub.status.idle":"2025-05-09T12:37:27.328900Z","shell.execute_reply.started":"2025-05-09T12:37:26.939319Z","shell.execute_reply":"2025-05-09T12:37:27.328210Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1458 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3bb97b2c8674bbe88e30b1e7dda9b67"}},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification\n\ndata_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, return_tensors=\"tf\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:37:29.281420Z","iopub.execute_input":"2025-05-09T12:37:29.281725Z","iopub.status.idle":"2025-05-09T12:37:29.286023Z","shell.execute_reply.started":"2025-05-09T12:37:29.281703Z","shell.execute_reply":"2025-05-09T12:37:29.285240Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"import evaluate\n\nseqeval = evaluate.load(\"seqeval\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:37:29.693012Z","iopub.execute_input":"2025-05-09T12:37:29.693808Z","iopub.status.idle":"2025-05-09T12:37:34.938428Z","shell.execute_reply.started":"2025-05-09T12:37:29.693774Z","shell.execute_reply":"2025-05-09T12:37:34.937551Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"123bd185b049413b9896148d0badad57"}},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"example = train_dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:37:37.980288Z","iopub.execute_input":"2025-05-09T12:37:37.980927Z","iopub.status.idle":"2025-05-09T12:37:37.985616Z","shell.execute_reply.started":"2025-05-09T12:37:37.980880Z","shell.execute_reply":"2025-05-09T12:37:37.984720Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"label_list=le.classes_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:37:56.017852Z","iopub.execute_input":"2025-05-09T12:37:56.018778Z","iopub.status.idle":"2025-05-09T12:37:56.022410Z","shell.execute_reply.started":"2025-05-09T12:37:56.018754Z","shell.execute_reply":"2025-05-09T12:37:56.021608Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"import numpy as np\n\nlabels = [label_list[i] for i in example[f\"pos_tags\"]]\n\n\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n\n    true_predictions = [\n        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"],\n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"],\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:38:02.043770Z","iopub.execute_input":"2025-05-09T12:38:02.044375Z","iopub.status.idle":"2025-05-09T12:38:02.050585Z","shell.execute_reply.started":"2025-05-09T12:38:02.044349Z","shell.execute_reply":"2025-05-09T12:38:02.049681Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"from transformers import create_optimizer\n\nbatch_size = 16\nnum_train_epochs = 3\nnum_train_steps = (len(train_dataset) // batch_size) * num_train_epochs\noptimizer, lr_schedule = create_optimizer(\n    init_lr=2e-5,\n    num_train_steps=num_train_steps,\n    weight_decay_rate=0.01,\n    num_warmup_steps=0,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:38:05.285087Z","iopub.execute_input":"2025-05-09T12:38:05.285364Z","iopub.status.idle":"2025-05-09T12:38:05.295019Z","shell.execute_reply.started":"2025-05-09T12:38:05.285346Z","shell.execute_reply":"2025-05-09T12:38:05.294330Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"print(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:38:07.377453Z","iopub.execute_input":"2025-05-09T12:38:07.377704Z","iopub.status.idle":"2025-05-09T12:38:07.381776Z","shell.execute_reply.started":"2025-05-09T12:38:07.377686Z","shell.execute_reply":"2025-05-09T12:38:07.380977Z"}},"outputs":[{"name":"stdout","text":"<transformers.models.bert.modeling_tf_bert.TFBertForTokenClassification object at 0x7a476cc503d0>\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"tf_train_set = model.prepare_tf_dataset (\n   tokenized_train,\n    shuffle=True,\n    batch_size=16,\n    collate_fn=data_collator,\n)\n\ntf_validation_set = model.prepare_tf_dataset (\n    tokenized_val,\n    shuffle=False,\n    batch_size=16,\n    collate_fn=data_collator,\n)\ntf_test_set = model.prepare_tf_dataset (\n    tokenized_test,\n    shuffle=False,\n    batch_size=16,\n    collate_fn=data_collator,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:38:12.271586Z","iopub.execute_input":"2025-05-09T12:38:12.271865Z","iopub.status.idle":"2025-05-09T12:38:12.889570Z","shell.execute_reply.started":"2025-05-09T12:38:12.271843Z","shell.execute_reply":"2025-05-09T12:38:12.888897Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"import tensorflow as tf\n\nmodel.compile(optimizer=optimizer)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:38:14.961314Z","iopub.execute_input":"2025-05-09T12:38:14.961635Z","iopub.status.idle":"2025-05-09T12:38:14.983372Z","shell.execute_reply.started":"2025-05-09T12:38:14.961611Z","shell.execute_reply":"2025-05-09T12:38:14.982496Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"from transformers.keras_callbacks import KerasMetricCallback\n\nmetric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:38:18.028709Z","iopub.execute_input":"2025-05-09T12:38:18.029594Z","iopub.status.idle":"2025-05-09T12:38:18.048032Z","shell.execute_reply.started":"2025-05-09T12:38:18.029559Z","shell.execute_reply":"2025-05-09T12:38:18.047201Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"!git config --global user.email \"lolo.hussien861@gmail.com\"\n!git config --global user.name \"Alaa hussien\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:38:23.449983Z","iopub.execute_input":"2025-05-09T12:38:23.450726Z","iopub.status.idle":"2025-05-09T12:38:23.853722Z","shell.execute_reply.started":"2025-05-09T12:38:23.450699Z","shell.execute_reply":"2025-05-09T12:38:23.852794Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:39:40.705999Z","iopub.execute_input":"2025-05-09T12:39:40.706344Z","iopub.status.idle":"2025-05-09T12:39:40.731875Z","shell.execute_reply.started":"2025-05-09T12:39:40.706314Z","shell.execute_reply":"2025-05-09T12:39:40.731048Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32a1acfaed8647d4bf342bba34e18078"}},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"from transformers.keras_callbacks import PushToHubCallback\n\npush_to_hub_callback = PushToHubCallback(\n    output_dir=\"Part_of_speech_arabic\",\n    tokenizer=tokenizer,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:40:07.384067Z","iopub.execute_input":"2025-05-09T12:40:07.384683Z","iopub.status.idle":"2025-05-09T12:40:10.176473Z","shell.execute_reply.started":"2025-05-09T12:40:07.384660Z","shell.execute_reply":"2025-05-09T12:40:10.175833Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\nFor more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n  warnings.warn(warning_message, FutureWarning)\nCloning https://huggingface.co/AlaaHussien/Part_of_speech_arabic into local empty directory.\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"callbacks = [metric_callback,push_to_hub_callback]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:40:12.317321Z","iopub.execute_input":"2025-05-09T12:40:12.318009Z","iopub.status.idle":"2025-05-09T12:40:12.321314Z","shell.execute_reply.started":"2025-05-09T12:40:12.317987Z","shell.execute_reply":"2025-05-09T12:40:12.320557Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=3, callbacks=callbacks)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:40:16.434436Z","iopub.execute_input":"2025-05-09T12:40:16.434726Z","iopub.status.idle":"2025-05-09T12:46:25.718094Z","shell.execute_reply.started":"2025-05-09T12:40:16.434707Z","shell.execute_reply":"2025-05-09T12:46:25.717222Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n265/265 [==============================] - ETA: 0s - loss: 0.4216","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SYM seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"265/265 [==============================] - 140s 408ms/step - loss: 0.4216 - val_loss: 0.1348 - precision: 0.9514 - recall: 0.9449 - f1: 0.9482 - accuracy: 0.9634\nEpoch 2/3\n265/265 [==============================] - ETA: 0s - loss: 0.1180","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SYM seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"265/265 [==============================] - 106s 399ms/step - loss: 0.1180 - val_loss: 0.1149 - precision: 0.9579 - recall: 0.9522 - f1: 0.9551 - accuracy: 0.9686\nEpoch 3/3\n265/265 [==============================] - ETA: 0s - loss: 0.0974","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NOUN seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADJ seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PUNCT seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: NUM seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADP seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: CCONJ seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: VERB seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PRON seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: AUX seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: DET seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PROPN seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ADV seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SCONJ seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PART seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: SYM seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: INTJ seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"265/265 [==============================] - 105s 398ms/step - loss: 0.0974 - val_loss: 0.1114 - precision: 0.9599 - recall: 0.9546 - f1: 0.9572 - accuracy: 0.9701\n","output_type":"stream"},{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"<tf_keras.src.callbacks.History at 0x7a476a845d50>"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"loss=model.evaluate(tf_test_set)\nprint(loss)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:46:55.174168Z","iopub.execute_input":"2025-05-09T12:46:55.174481Z","iopub.status.idle":"2025-05-09T12:46:57.433594Z","shell.execute_reply.started":"2025-05-09T12:46:55.174460Z","shell.execute_reply":"2025-05-09T12:46:57.432806Z"}},"outputs":[{"name":"stdout","text":"23/23 [==============================] - 2s 96ms/step - loss: 0.1277\n0.12770117819309235\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"result = ' '.join(review_sentences[0])  \nprint(result)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T13:07:22.876744Z","iopub.execute_input":"2025-05-09T13:07:22.877705Z","iopub.status.idle":"2025-05-09T13:07:22.882448Z","shell.execute_reply.started":"2025-05-09T13:07:22.877671Z","shell.execute_reply":"2025-05-09T13:07:22.881697Z"}},"outputs":[{"name":"stdout","text":"برلين ترفض حصول شركة اميركية على رخصة تصنيع دبابة \" ليوبارد \" الالمانية\n","output_type":"stream"}],"execution_count":75},{"cell_type":"code","source":"result = ' '.join(pos_tags[0])  \nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T13:06:58.932884Z","iopub.execute_input":"2025-05-09T13:06:58.933875Z","iopub.status.idle":"2025-05-09T13:06:58.938329Z","shell.execute_reply.started":"2025-05-09T13:06:58.933848Z","shell.execute_reply":"2025-05-09T13:06:58.937617Z"}},"outputs":[{"name":"stdout","text":"X VERB NOUN NOUN ADJ ADP NOUN NOUN NOUN PUNCT X PUNCT ADJ\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"from transformers import pipeline\n\npipe = pipeline(\"token-classification\", model=\"AlaaHussien/Part_of_speech_arabic\")\npipe(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T13:07:25.824972Z","iopub.execute_input":"2025-05-09T13:07:25.825487Z","iopub.status.idle":"2025-05-09T13:07:27.448060Z","shell.execute_reply.started":"2025-05-09T13:07:25.825466Z","shell.execute_reply":"2025-05-09T13:07:27.447394Z"}},"outputs":[{"name":"stderr","text":"Some layers from the model checkpoint at AlaaHussien/Part_of_speech_arabic were not used when initializing TFBertForTokenClassification: ['dropout_37']\n- This IS expected if you are initializing TFBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFBertForTokenClassification were initialized from the model checkpoint at AlaaHussien/Part_of_speech_arabic.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\nDevice set to use 0\nAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"[{'entity': 'X',\n  'score': 0.9930369,\n  'index': 1,\n  'word': 'برلين',\n  'start': 0,\n  'end': 5},\n {'entity': 'VERB',\n  'score': 0.99469537,\n  'index': 2,\n  'word': 'ترفض',\n  'start': 6,\n  'end': 10},\n {'entity': 'NOUN',\n  'score': 0.9884835,\n  'index': 3,\n  'word': 'حصول',\n  'start': 11,\n  'end': 15},\n {'entity': 'NOUN',\n  'score': 0.9978123,\n  'index': 4,\n  'word': 'شركة',\n  'start': 16,\n  'end': 20},\n {'entity': 'ADJ',\n  'score': 0.9831988,\n  'index': 5,\n  'word': 'اميركية',\n  'start': 21,\n  'end': 28},\n {'entity': 'ADP',\n  'score': 0.99734026,\n  'index': 6,\n  'word': 'على',\n  'start': 29,\n  'end': 32},\n {'entity': 'NOUN',\n  'score': 0.99659014,\n  'index': 7,\n  'word': 'رخصة',\n  'start': 33,\n  'end': 37},\n {'entity': 'NOUN',\n  'score': 0.9923678,\n  'index': 8,\n  'word': 'تصنيع',\n  'start': 38,\n  'end': 43},\n {'entity': 'NOUN',\n  'score': 0.9768653,\n  'index': 9,\n  'word': 'دب',\n  'start': 44,\n  'end': 46},\n {'entity': 'NOUN',\n  'score': 0.9731041,\n  'index': 10,\n  'word': '##ابة',\n  'start': 46,\n  'end': 49},\n {'entity': 'PUNCT',\n  'score': 0.99747604,\n  'index': 11,\n  'word': '\"',\n  'start': 50,\n  'end': 51},\n {'entity': 'X',\n  'score': 0.9943579,\n  'index': 12,\n  'word': 'ليو',\n  'start': 52,\n  'end': 55},\n {'entity': 'X',\n  'score': 0.99155396,\n  'index': 13,\n  'word': '##بار',\n  'start': 55,\n  'end': 58},\n {'entity': 'X',\n  'score': 0.9896316,\n  'index': 14,\n  'word': '##د',\n  'start': 58,\n  'end': 59},\n {'entity': 'PUNCT',\n  'score': 0.9977049,\n  'index': 15,\n  'word': '\"',\n  'start': 60,\n  'end': 61},\n {'entity': 'ADJ',\n  'score': 0.969331,\n  'index': 16,\n  'word': 'الالمانية',\n  'start': 62,\n  'end': 71}]"},"metadata":{}}],"execution_count":76},{"cell_type":"code","source":"text=\"محمد ذهب الى الملعب\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:55:53.079599Z","iopub.execute_input":"2025-05-09T12:55:53.079940Z","iopub.status.idle":"2025-05-09T12:55:53.083840Z","shell.execute_reply.started":"2025-05-09T12:55:53.079903Z","shell.execute_reply":"2025-05-09T12:55:53.083254Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"from transformers import pipeline\n\npipe = pipeline(\"token-classification\", model=\"AlaaHussien/Part_of_speech_arabic\")\npipe(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:55:54.211114Z","iopub.execute_input":"2025-05-09T12:55:54.211467Z","iopub.status.idle":"2025-05-09T12:55:55.899746Z","shell.execute_reply.started":"2025-05-09T12:55:54.211438Z","shell.execute_reply":"2025-05-09T12:55:55.898829Z"}},"outputs":[{"name":"stderr","text":"Some layers from the model checkpoint at AlaaHussien/Part_of_speech_arabic were not used when initializing TFBertForTokenClassification: ['dropout_37']\n- This IS expected if you are initializing TFBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFBertForTokenClassification were initialized from the model checkpoint at AlaaHussien/Part_of_speech_arabic.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\nDevice set to use 0\nAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"[{'entity': 'X',\n  'score': 0.86801434,\n  'index': 1,\n  'word': 'محمد',\n  'start': 0,\n  'end': 4},\n {'entity': 'VERB',\n  'score': 0.98758763,\n  'index': 2,\n  'word': 'ذهب',\n  'start': 5,\n  'end': 8},\n {'entity': 'ADP',\n  'score': 0.9981111,\n  'index': 3,\n  'word': 'الى',\n  'start': 9,\n  'end': 12},\n {'entity': 'NOUN',\n  'score': 0.9909791,\n  'index': 4,\n  'word': 'الملعب',\n  'start': 13,\n  'end': 19}]"},"metadata":{}}],"execution_count":68},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}